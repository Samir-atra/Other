{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Samir-atra/Other/blob/main/Capsa_experience/Capsa_Copy_of_Train%26Test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6vfxK_0Ptlr"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import numpy as np\n",
        "import os\n",
        "import pathlib\n",
        "import IPython\n",
        "import sys\n",
        "!pip install keras_tuner -q\n",
        "import keras_tuner\n",
        "!pip install git+https://github.com/themis-ai/capsa.git\n",
        "import capsa\n",
        "from capsa import EnsembleWrapper, DropoutWrapper, VAEWrapper\n",
        "!pip install helper\n",
        "import helper\n",
        "\n",
        "from google.colab import drive             \n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfp3guitPtlt"
      },
      "outputs": [],
      "source": [
        "# Dataset loading\n",
        "\n",
        "data_path = pathlib.Path('/content/drive/MyDrive/archiveX3/Training/')\n",
        "data_path_test = pathlib.Path('/content/drive/MyDrive/archiveX3/Testing/')\n",
        "\n",
        "dataset_path = tf.keras.utils.image_dataset_from_directory(\n",
        "    data_path,\n",
        "    labels= 'inferred',\n",
        "    validation_split=0.2,\n",
        "    subset='training',\n",
        "    seed= 1,\n",
        "    batch_size=64,\n",
        "    image_size=(64, 64),\n",
        "    color_mode=\"rgb\")\n",
        "    # shuffle=True)\n",
        "\n",
        "dataset_path_val = tf.keras.utils.image_dataset_from_directory(\n",
        "    data_path,\n",
        "    labels= 'inferred',\n",
        "    validation_split=0.2,\n",
        "    subset='validation',\n",
        "    seed= 2,\n",
        "    batch_size=64,\n",
        "    image_size=(64, 64),\n",
        "    color_mode=\"rgb\")\n",
        "    # shuffle=True)\n",
        "\n",
        "dataset_path_test = tf.keras.utils.image_dataset_from_directory(\n",
        "    data_path_test,\n",
        "    labels= 'inferred',\n",
        "    seed= 3,\n",
        "    batch_size=64,\n",
        "    image_size=(64, 64),\n",
        "    color_mode=\"rgb\")\n",
        "    # shuffle=True)\n",
        "\n",
        "efficientnet_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "    data_path,\n",
        "    labels= 'inferred',\n",
        "    seed= 3,\n",
        "    batch_size=64,\n",
        "    image_size=(240, 240),\n",
        "    color_mode=\"rgb\")\n",
        "\n",
        "# efficientnet_dataset_val = tf.keras.utils.image_dataset_from_directory(\n",
        "#     data_path,\n",
        "#     labels= 'inferred',\n",
        "#     seed= 3,\n",
        "#     batch_size=64,\n",
        "#     image_size=(240, 240),\n",
        "#     color_mode=\"rgb\")\n",
        "\n",
        "num_classes = 1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoder, Decoder, and transfer learning base model\n",
        "\n",
        "\n",
        "encoder = tf.keras.Sequential([\n",
        "    tf.keras.Input(shape=(64, 64, 3)),\n",
        "    tf.keras.layers.Conv2D(16, 3, strides = 2, padding = \"same\",  activation='relu'),#, kernel_regularizer=tf.keras.regularizers.l2(0.001)),  \n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.5),                                                                         #DP1\n",
        "    tf.keras.layers.Conv2D(32, 3, strides = 2, padding = \"same\", activation='relu'),#, kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.5),                                                                         #DP2\n",
        "    tf.keras.layers.Conv2D(64, 3, strides = 2, padding = \"same\", activation='relu'),#, kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Conv2D(128, 1, strides = 2, padding = \"same\", activation='relu'),#, kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.7),                                                                         #DP3\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(units = 512, activation='relu'),#, kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
        "    tf.keras.layers.Dropout(0.2),                                                                         #DP4                                                                        #DP5\n",
        "    tf.keras.layers.Dense(num_classes, activation= None)\n",
        "])\n",
        "\n",
        "\n",
        "decoder = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(units=4*4*128),  \n",
        "        tf.keras.layers.Reshape((4, 4, 128)),\n",
        "        tf.keras.layers.Conv2DTranspose(64, 1,  strides=2, padding = \"same\", activation='relu'),\n",
        "        tf.keras.layers.Conv2DTranspose(32, 3,  strides=2, padding = \"same\", activation='relu'),\n",
        "        tf.keras.layers.Conv2DTranspose(16, 3,  strides=2, padding = \"same\", activation='relu'),\n",
        "        tf.keras.layers.Conv2DTranspose(3, 3,  strides=2, padding = \"same\"),\n",
        "    ])\n",
        "\n",
        "base_model = tf.keras.Sequential([\n",
        "    hub.KerasLayer(\"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_b1/feature_vector/2\", trainable=False),  \n",
        "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "base_model.build([None, 240, 240, 3]) \n"
      ],
      "metadata": {
        "id": "HqkZqKoNbKMh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# HistogramVAE Wrapper\n",
        "\n",
        "wrapped_model = capsa.HistogramVAEWrapper(encoder, num_bins=5, queue_size=20000, latent_dim = 64, decoder=decoder)\n",
        "\n",
        "wrapped_model.compile(\n",
        "    optimizer= tf.keras.optimizers.Adam(learning_rate = 0.001),\n",
        "    loss= tf.losses.BinaryCrossentropy(from_logits= True),\n",
        "    metrics= [tf.keras.metrics.BinaryAccuracy()]\n",
        ")\n",
        "\n",
        "\n",
        "history = wrapped_model.fit(\n",
        "    dataset_path,\n",
        "    epochs=30,                                    \n",
        "    validation_data = dataset_path_val)\n",
        "\n",
        "\n",
        "out = wrapped_model.predict(dataset_path_test, batch_size=512)\n"
      ],
      "metadata": {
        "id": "iRcBsS7hk17a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MVE Wrapper\n",
        "\n",
        "mve_model = capsa.MVEWrapper(encoder, is_classification=True)\n",
        "# mve_model = capsa.MVEWrapper(base_model, is_classification=True)\n",
        "\n",
        "\n",
        "mve_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=5e-4),\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), \n",
        "    metrics=[tf.keras.metrics.BinaryAccuracy()], \n",
        "    run_eagerly=True\n",
        ")\n",
        "\n",
        "history = mve_model.fit(\n",
        "        dataset_path,\n",
        "        epochs=6,\n",
        "        batch_size=64,\n",
        "  )\n",
        "\n",
        "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
        "normalized_train_ds = dataset_path.map(lambda x, y: (normalization_layer(x), y))\n",
        "normalized_test_ds = dataset_path_test.map(lambda x, y: (normalization_layer(x), y))\n",
        "\n",
        "images = np.vstack((normalized_test_ds, normalized_train_ds))\n"
      ],
      "metadata": {
        "id": "Pq5nyLc-JMYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensemble Wrapper\n",
        "\n",
        "Ensemble_wrapped_model = EnsembleWrapper(encoder, num_members=1)\n",
        "\n",
        "\n",
        "Ensemble_wrapped_model.compile(\n",
        "            optimizer=tf.keras.optimizers.Adam(),\n",
        "            loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "            metrics=[tf.keras.metrics.BinaryAccuracy()]\n",
        "                     )\n",
        "\n",
        "history = Ensemble_wrapped_model.fit(\n",
        "        dataset_path,\n",
        "        epochs=12,\n",
        "        batch_size=64,\n",
        "  )\n",
        "\n"
      ],
      "metadata": {
        "id": "hmGa4UoEwuwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropout Wrapper\n",
        "\n",
        "dropout_model = DropoutWrapper(encoder, p=0.5)\n",
        "# dropout_model = DropoutWrapper(base_model, p=0.5)\n",
        "\n",
        "\n",
        "dropout_model.compile(\n",
        "            optimizer=tf.keras.optimizers.Adam(learning_rate = 0.0001),\n",
        "            loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "            metrics=[tf.keras.metrics.BinaryAccuracy()]\n",
        "                     )\n",
        "\n",
        "history = dropout_model.fit(\n",
        "        efficientnet_dataset,\n",
        "        epochs=12,\n",
        "        batch_size=64,\n",
        "  )"
      ],
      "metadata": {
        "id": "eoOywcJC4Oka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# VAE Wrapper\n",
        "\n",
        "vae_model = VAEWrapper(encoder, decoder=decoder)\n",
        "\n",
        "vae_model.compile(\n",
        "    optimizer= tf.keras.optimizers.Adam(learning_rate = 0.0000001),\n",
        "    loss= tf.losses.BinaryCrossentropy(from_logits= True),\n",
        "    metrics= [tf.keras.metrics.BinaryAccuracy()]\n",
        ")\n",
        "\n",
        "history = vae_model.fit(\n",
        "    dataset_path,\n",
        "    epochs=3,                                    \n",
        "    validation_data = dataset_path_val)\n",
        "\n"
      ],
      "metadata": {
        "id": "hUCeEc6jiODR"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.9.7 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "d4de0671d8054c88a8842951ed8f6115b974e2e5b39cbc2553be5a6678282e63"
      }
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}